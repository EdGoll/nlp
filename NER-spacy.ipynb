{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python394jvsc74a57bd05f32b46b154a184afd9e753b821bd49119defb768fad04c1245ac055f31252d7",
   "display_name": "Python 3.9.4 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "5f32b46b154a184afd9e753b821bd49119defb768fad04c1245ac055f31252d7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n"
     ]
    }
   ],
   "source": [
    "import docx2txt\n",
    "import docx\n",
    "from docx2python import docx2python\n",
    "from os import path\n",
    "from spacy import displacy\n",
    "from spacy.gold import GoldParse\n",
    "from spacy.scorer import Scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(ner_model, examples):\n",
    "    scorer = Scorer()\n",
    "    for input_, annot in examples:\n",
    "        doc_gold_text = ner_model.make_doc(input_)\n",
    "        gold = GoldParse(doc_gold_text, entities=annot)\n",
    "        pred_value = ner_model(input_)\n",
    "        scorer.score(pred_value, gold)\n",
    "    return scorer.score\n",
    "\n",
    "def get_files_from_path(path):\n",
    "    archives = os.listdir(path)\n",
    "    return archives\n",
    "\n",
    "def get_text_hall_imp(path_file):      \n",
    "    hallazgos_text_arr = []\n",
    "    impresion_text_arr = []\n",
    "    str_token =':'\n",
    "    hallazgos_text = ''\n",
    "    impresion_text = ''\n",
    "    doc = docx.Document(path_file)\n",
    "    all_paras = doc.paragraphs\n",
    "    len(all_paras)\n",
    "         \n",
    "    for para in all_paras:        \n",
    "       #print(\"-------\")\n",
    "       #print('parrafo-> '+para.text)\n",
    "       if para.text == 'Hallazgos:' :\n",
    "           str_token ='Hallazgos:'\n",
    "           continue\n",
    "\n",
    "       if str_token == 'Hallazgos:' and para.text != '':\n",
    "           #print(\"Hallazgos \"+para.text)  \n",
    "           if 'Impresi贸n:' in para.text:                \n",
    "               str_token ='Impresi贸n:'\n",
    "               continue\n",
    "           else:\n",
    "               #print(\"Hallazgos \"+para.text)  \n",
    "               #hallazgos_text += ''.join(para.text)\n",
    "               hallazgos_text_arr.append(para.text)\n",
    "               with open('output.txt', 'a',  encoding='utf-8') as f:\n",
    "                    f.write(para.text)\n",
    "\n",
    "       if str_token == 'Impresi贸n:' and para.text != '' :\n",
    "           #if para.text not in 'BIRADS':\n",
    "           if para.text.find(\"BIRADS\") == -1:\n",
    "                #print(\"Impresi贸n \"+para.text)\n",
    "                #impresion_text += ''.join(para.text)\n",
    "                impresion_text_arr.append(para.text)\n",
    "                with open('output.txt', 'a',  encoding='utf-8') as f:\n",
    "                    f.write(para.text)\n",
    "           else :\n",
    "                break\n",
    "\n",
    "    return impresion_text_arr, hallazgos_text_arr\n",
    " \n",
    "def eval_ner(doc):\n",
    "    ners = []\n",
    "    #print(doc.ents)\n",
    "    for e in doc.ents:\n",
    "        #print(e.label_, e.text) \n",
    "        ners.append({e.label_, e.text})\n",
    "    return ners\n",
    "\n",
    "def view_ner_text(doc):\n",
    "    displacy.render(doc,style=\"ent\", jupyter=True)   \n",
    "\n",
    "def find_name(list, name):\n",
    "     return next((item for item in list.ents if item.label_ == name), None)\n",
    "     \n",
    "def find_name_range(list, substring, start, end):\n",
    "     return next((item for item in list.ents if item.label_.find(substring) != -1 ), None)\n",
    "\n",
    "def proc_ner_array(doc):\n",
    "    #for item in ner_arr:\n",
    "    if find_name(doc, 'NEGACION') == None  and (find_name_range(doc, 'H_',0,2) != None and ( find_name_range(doc, 'M_',0,2) != None  or find_name_range(doc, 'C_',0,2) != None )): \n",
    "        for e in doc.ents:\n",
    "            print(e.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('data/output/model-best')\n",
    "m_lado = {'M_DER' , 'M_IZQ' , 'M_AMBAS'}\n",
    "cuad = {'C_SUP_EX' ,'C_SUP_IN' , 'C_INF_EX' , 'C_INF_IN' , 'C_CENTRO_SUP' , 'C_CENTRO_INF' , 'C_CENTRAL' , 'C_RETROAREOLA' , 'C_AXILAR'}\n",
    "hall = {'H_MASA' , 'H_NODULO' , 'H_MICROCAL' , 'H_ASIMETRIA' , 'H_AUM_DENSIDAD' , 'H_ADENOPATIA' , 'H_DISTORCION' , 'H_ENG_CUTANEO' , 'H_RETRAC_CUTANEA' , 'H_RETRAC_PEZON'}\n",
    "neg ={'NEGACION'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dir_docx=\"e:/workspace/python/FONDEF/MamAI/src/ejemplos_aleatorios\"\n",
    "archives = get_files_from_path(dir_docx)\n",
    "\n",
    "docx_json = []\n",
    "for file in archives :\n",
    "    impresion_text_arr, hallazgos_text_arr = get_text_hall_imp(dir_docx+\"\\\\\"+file)    \n",
    "    docx_json.append({\"file_docx\":file,  'impresiones' : impresion_text_arr, 'hallazgos':hallazgos_text_arr})\n",
    "#print(len(docx_json))\n",
    "#print(docx_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "******************102282053.docx**********************\n",
      "----------Parrafo:-------------------\n",
      "----------Parrafo:-------------------\n",
      "M_DER\n",
      "C_SUP_EX\n",
      "H_NODULO\n",
      "H_NODULO\n",
      "C_INF_EX\n",
      "----------Parrafo:-------------------\n",
      "******************102290788.docx**********************\n",
      "----------Parrafo:-------------------\n",
      "H_NODULO\n",
      "C_INF_IN\n",
      "M_DER\n",
      "******************109277270.docx**********************\n",
      "----------Parrafo:-------------------\n",
      "----------Parrafo:-------------------\n",
      "----------Parrafo:-------------------\n",
      "----------Parrafo:-------------------\n",
      "M_AMBAS\n",
      "H_MICROCAL\n",
      "----------Parrafo:-------------------\n",
      "C_SUP_EX\n",
      "M_IZQ\n",
      "H_MICROCAL\n",
      "----------Parrafo:-------------------\n",
      "******************109295941.docx**********************\n",
      "----------Parrafo:-------------------\n",
      "----------Parrafo:-------------------\n",
      "----------Parrafo:-------------------\n",
      "----------Parrafo:-------------------\n",
      "M_DER\n",
      "H_NODULO\n",
      "******************115298186.docx**********************\n",
      "----------Parrafo:-------------------\n",
      "----------Parrafo:-------------------\n",
      "----------Parrafo:-------------------\n",
      "----------Parrafo:-------------------\n",
      "----------Parrafo:-------------------\n",
      "******************12276284.docx**********************\n",
      "----------Parrafo:-------------------\n",
      "----------Parrafo:-------------------\n",
      "----------Parrafo:-------------------\n",
      "----------Parrafo:-------------------\n",
      "H_NODULO\n",
      "C_SUP_EX\n",
      "M_DER\n",
      "----------Parrafo:-------------------\n",
      "----------Parrafo:-------------------\n",
      "******************124277022.docx**********************\n",
      "----------Parrafo:-------------------\n",
      "----------Parrafo:-------------------\n",
      "----------Parrafo:-------------------\n",
      "******************135297250.docx**********************\n",
      "----------Parrafo:-------------------\n",
      "----------Parrafo:-------------------\n",
      "----------Parrafo:-------------------\n",
      "----------Parrafo:-------------------\n",
      "H_NODULO\n",
      "C_AXILAR\n",
      "M_IZQ\n",
      "----------Parrafo:-------------------\n",
      "******************147297140.docx**********************\n",
      "----------Parrafo:-------------------\n",
      "----------Parrafo:-------------------\n",
      "----------Parrafo:-------------------\n",
      "----------Parrafo:-------------------\n",
      "----------Parrafo:-------------------\n",
      "******************153289774.docx**********************\n",
      "----------Parrafo:-------------------\n",
      "----------Parrafo:-------------------\n",
      "----------Parrafo:-------------------\n",
      "----------Parrafo:-------------------\n",
      "******************157292605.docx**********************\n",
      "----------Parrafo:-------------------\n",
      "----------Parrafo:-------------------\n",
      "H_DISTORCION\n",
      "C_CENTRAL\n",
      "----------Parrafo:-------------------\n",
      "******************163280438.docx**********************\n",
      "----------Parrafo:-------------------\n",
      "----------Parrafo:-------------------\n",
      "******************166284494.docx**********************\n",
      "----------Parrafo:-------------------\n",
      "----------Parrafo:-------------------\n",
      "----------Parrafo:-------------------\n",
      "----------Parrafo:-------------------\n",
      "******************167283169.docx**********************\n",
      "----------Parrafo:-------------------\n",
      "----------Parrafo:-------------------\n",
      "----------Parrafo:-------------------\n",
      "----------Parrafo:-------------------\n",
      "----------Parrafo:-------------------\n",
      "----------Parrafo:-------------------\n",
      "----------Parrafo:-------------------\n",
      "----------Parrafo:-------------------\n",
      "----------Parrafo:-------------------\n",
      "----------Parrafo:-------------------\n",
      "----------Parrafo:-------------------\n",
      "----------Parrafo:-------------------\n",
      "----------Parrafo:-------------------\n",
      "******************17278309.docx**********************\n",
      "----------Parrafo:-------------------\n",
      "----------Parrafo:-------------------\n",
      "C_SUP_EX\n",
      "H_NODULO\n",
      "----------Parrafo:-------------------\n",
      "******************176272494.docx**********************\n",
      "----------Parrafo:-------------------\n",
      "----------Parrafo:-------------------\n",
      "----------Parrafo:-------------------\n",
      "----------Parrafo:-------------------\n",
      "----------Parrafo:-------------------\n",
      "----------Parrafo:-------------------\n",
      "----------Parrafo:-------------------\n",
      "----------Parrafo:-------------------\n",
      "----------Parrafo:-------------------\n",
      "----------Parrafo:-------------------\n",
      "******************178295088.docx**********************\n",
      "----------Parrafo:-------------------\n",
      "----------Parrafo:-------------------\n",
      "----------Parrafo:-------------------\n",
      "----------Parrafo:-------------------\n",
      "******************189292757.docx**********************\n",
      "----------Parrafo:-------------------\n",
      "----------Parrafo:-------------------\n",
      "----------Parrafo:-------------------\n",
      "----------Parrafo:-------------------\n",
      "----------Parrafo:-------------------\n",
      "----------Parrafo:-------------------\n",
      "----------Parrafo:-------------------\n",
      "----------Parrafo:-------------------\n",
      "H_DISTORCION\n",
      "C_CENTRAL\n",
      "M_IZQ\n",
      "H_MICROCAL\n",
      "----------Parrafo:-------------------\n",
      "----------Parrafo:-------------------\n",
      "----------Parrafo:-------------------\n",
      "----------Parrafo:-------------------\n",
      "----------Parrafo:-------------------\n",
      "----------Parrafo:-------------------\n",
      "******************192286883.docx**********************\n",
      "----------Parrafo:-------------------\n",
      "----------Parrafo:-------------------\n",
      "----------Parrafo:-------------------\n",
      "******************19277110.docx**********************\n",
      "----------Parrafo:-------------------\n",
      "----------Parrafo:-------------------\n",
      "----------Parrafo:-------------------\n"
     ]
    }
   ],
   "source": [
    "informes_out = []\n",
    "cuadrante_out = []\n",
    "hallazgos_out = []\n",
    "ladomama_out = []\n",
    "parrafo_out = []\n",
    "\n",
    "informes = ''\n",
    "cuadrante = ''\n",
    "hallazgo = ''\n",
    "ladomama = ''\n",
    "parrafo = ''\n",
    "\n",
    "ners = []\n",
    "docx_json = docx_json[:20]\n",
    "for i in range(len(docx_json)):   \n",
    "    num_ora = 0\n",
    "    print('******************'+docx_json[i]['file_docx']+'**********************') \n",
    "    for parraph in  docx_json[i]['hallazgos'] :\n",
    "        num_ora += 1 \n",
    "        doc = nlp(parraph.lower() )       \n",
    "        print('----------Parrafo:-------------------') \n",
    "        #ners = eval_ner(doc)\n",
    "        #proc_ner_array(ners)\n",
    "        proc_ner_array(doc)\n",
    "        #print(ners)\n",
    "        #view_ner_text(doc) \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(informes_out))\n",
    "print(len(ladomama_out))\n",
    "print(len(cuadrante_out))\n",
    "print(len(parrafo_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "json_obj_excel = {'Informe':informes_out, 'Lugar': ladomama_out, 'Ubicacion': cuadrante_out,'Hallazgo':hallazgos_out, 'Texto' : parrafo_out} \n",
    "df = pd.DataFrame(json_obj_excel).to_excel(\"out_excel_ner.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(docx_json[2]['hallazgos'][4])\n",
    "print(doc.ents)  \n",
    "view_ner_text(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 116
    }
   ],
   "source": [
    "my_string = \"M_HALL\"\n",
    "my_string.find(\"M_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}