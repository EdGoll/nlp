{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python392jvsc74a57bd063fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d",
   "display_name": "Python 3.9.2 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting sentence-transformers\n  Downloading sentence-transformers-1.0.4.tar.gz (74 kB)\nRequirement already satisfied: transformers<5.0.0,>=3.1.0 in c:\\python39\\lib\\site-packages (from sentence-transformers) (4.4.2)\nRequirement already satisfied: tqdm in c:\\python39\\lib\\site-packages (from sentence-transformers) (4.59.0)\nRequirement already satisfied: torch>=1.6.0 in c:\\python39\\lib\\site-packages (from sentence-transformers) (1.8.1)\nRequirement already satisfied: numpy in c:\\python39\\lib\\site-packages (from sentence-transformers) (1.20.2)\nRequirement already satisfied: scikit-learn in c:\\python39\\lib\\site-packages (from sentence-transformers) (0.24.1)\nRequirement already satisfied: scipy in c:\\python39\\lib\\site-packages (from sentence-transformers) (1.6.2)\nRequirement already satisfied: nltk in c:\\python39\\lib\\site-packages (from sentence-transformers) (3.4.1)\nCollecting sentencepiece\n  Downloading sentencepiece-0.1.95-cp39-cp39-win_amd64.whl (1.2 MB)\nRequirement already satisfied: typing-extensions in c:\\python39\\lib\\site-packages (from torch>=1.6.0->sentence-transformers) (3.7.4.3)\nRequirement already satisfied: packaging in c:\\python39\\lib\\site-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (20.9)\nRequirement already satisfied: requests in c:\\python39\\lib\\site-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (2.25.1)\nRequirement already satisfied: tokenizers<0.11,>=0.10.1 in c:\\python39\\lib\\site-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (0.10.1)\nRequirement already satisfied: sacremoses in c:\\python39\\lib\\site-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (0.0.43)\nRequirement already satisfied: filelock in c:\\python39\\lib\\site-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (3.0.12)\nRequirement already satisfied: regex!=2019.12.17 in c:\\python39\\lib\\site-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (2021.3.17)\nRequirement already satisfied: six in c:\\python39\\lib\\site-packages (from nltk->sentence-transformers) (1.12.0)\nRequirement already satisfied: pyparsing>=2.0.2 in c:\\python39\\lib\\site-packages (from packaging->transformers<5.0.0,>=3.1.0->sentence-transformers) (2.4.7)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\python39\\lib\\site-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (1.26.4)\nRequirement already satisfied: chardet<5,>=3.0.2 in c:\\python39\\lib\\site-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (4.0.0)\nRequirement already satisfied: idna<3,>=2.5 in c:\\python39\\lib\\site-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (2.10)\nRequirement already satisfied: certifi>=2017.4.17 in c:\\python39\\lib\\site-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (2020.12.5)\nRequirement already satisfied: joblib in c:\\python39\\lib\\site-packages (from sacremoses->transformers<5.0.0,>=3.1.0->sentence-transformers) (1.0.1)\nRequirement already satisfied: click in c:\\python39\\lib\\site-packages (from sacremoses->transformers<5.0.0,>=3.1.0->sentence-transformers) (7.1.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in c:\\python39\\lib\\site-packages (from scikit-learn->sentence-transformers) (2.1.0)\nBuilding wheels for collected packages: sentence-transformers\n  Building wheel for sentence-transformers (setup.py): started\n  Building wheel for sentence-transformers (setup.py): finished with status 'done'\n  Created wheel for sentence-transformers: filename=sentence_transformers-1.0.4-py3-none-any.whl size=114306 sha256=b8975eb469d5b70996b8e41c731d6071cc26ec35fe23e39027e495d0f8afd531\n  Stored in directory: c:\\users\\eduardo\\appdata\\local\\pip\\cache\\wheels\\e7\\fc\\35\\51d4c35428e8770140d2fede607f9e6cf1cd3799d748b1168b\nSuccessfully built sentence-transformers\nInstalling collected packages: sentencepiece, sentence-transformers\nSuccessfully installed sentence-transformers-1.0.4 sentencepiece-0.1.95\n"
     ]
    }
   ],
   "source": [
    "#!pip install transformers\n",
    "#!pip install sklearn\n",
    "#!pip install nltk\n",
    "\n",
    "#import nltk\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "#!pip install sentence-transformers  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "def max_sum_sim(doc_embedding, word_embeddings, words, top_n, nr_candidates):\n",
    "    # Calculate distances and extract keywords\n",
    "    distances = cosine_similarity(doc_embedding, candidate_embeddings)\n",
    "    distances_candidates = cosine_similarity(candidate_embeddings, \n",
    "                                            candidate_embeddings)\n",
    "\n",
    "    # Get top_n words as candidates based on cosine similarity\n",
    "    words_idx = list(distances.argsort()[0][-nr_candidates:])\n",
    "    words_vals = [candidates[index] for index in words_idx]\n",
    "    distances_candidates = distances_candidates[np.ix_(words_idx, words_idx)]\n",
    "\n",
    "    # Calculate the combination of words that are the least similar to each other\n",
    "    min_sim = np.inf\n",
    "    candidate = None\n",
    "    for combination in itertools.combinations(range(len(words_idx)), top_n):\n",
    "        sim = sum([distances_candidates[i][j] for i in combination for j in combination if i != j])\n",
    "        if sim < min_sim:\n",
    "            candidate = combination\n",
    "            min_sim = sim\n",
    "\n",
    "    return [words_vals[idx] for idx in candidate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def mmr(doc_embedding, word_embeddings, words, top_n, diversity):\n",
    "\n",
    "    # Extract similarity within words, and between words and the document\n",
    "    word_doc_similarity = cosine_similarity(word_embeddings, doc_embedding)\n",
    "    word_similarity = cosine_similarity(word_embeddings)\n",
    "\n",
    "    # Initialize candidates and already choose best keyword/keyphras\n",
    "    keywords_idx = [np.argmax(word_doc_similarity)]\n",
    "    candidates_idx = [i for i in range(len(words)) if i != keywords_idx[0]]\n",
    "\n",
    "    for _ in range(top_n - 1):\n",
    "        # Extract similarities within candidates and\n",
    "        # between candidates and selected keywords/phrases\n",
    "        candidate_similarities = word_doc_similarity[candidates_idx, :]\n",
    "        target_similarities = np.max(word_similarity[candidates_idx][:, keywords_idx], axis=1)\n",
    "\n",
    "        # Calculate MMR\n",
    "        mmr = (1-diversity) * candidate_similarities - diversity * target_similarities.reshape(-1, 1)\n",
    "        mmr_idx = candidates_idx[np.argmax(mmr)]\n",
    "\n",
    "        # Update keywords & candidates\n",
    "        keywords_idx.append(mmr_idx)\n",
    "        candidates_idx.remove(mmr_idx)\n",
    "\n",
    "    return [words[idx] for idx in keywords_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc =\"\"\"Hallazgos: \n",
    "\n",
    "Mamas heterogéneamente densas. \n",
    "En la mama derecha, cuadrante supero externo, tercio posterior se observa parcialmente algunos contornos nodulares y a izquierda, también algunos nodulitos en cuadrantes inferiores, tercio posterior, los cuales no eran visibles en examen previo. \n",
    "Calcificaciones benignas en regiones axilares. \n",
    "Impresión:  \n",
    "Mamas densas con nódulos bilaterales. \n",
    "\n",
    "BIRADS 0.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "n_gram_range = (3, 3)\n",
    "stop_words = stopwords.words('spanish')\n",
    "\n",
    "# Extract candidate words/phrases\n",
    "count = CountVectorizer(ngram_range=n_gram_range, stop_words=stop_words).fit([doc])\n",
    "candidates = count.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('distilbert-base-nli-mean-tokens')\n",
    "doc_embedding = model.encode([doc])\n",
    "candidate_embeddings = model.encode(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "top_n = 5\n",
    "distances = cosine_similarity(doc_embedding, candidate_embeddings)\n",
    "keywords = [candidates[index] for index in distances.argsort()[0][-top_n:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['axilares impresión mamas',\n",
       " 'mamas densas nódulos',\n",
       " 'mama derecha cuadrante',\n",
       " 'mamas heterogéneamente densas',\n",
       " 'hallazgos mamas heterogéneamente']"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "keywords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['nodulares izquierda nodulitos',\n",
       " 'izquierda nodulitos cuadrantes',\n",
       " 'heterogéneamente densas mama',\n",
       " 'mamas densas nódulos',\n",
       " 'hallazgos mamas heterogéneamente']"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "max_sum_sim(doc_embedding, candidate_embeddings, candidates, top_n=5, nr_candidates=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['nódulos bilaterales birads',\n",
       " 'previo calcificaciones benignas',\n",
       " 'externo tercio posterior',\n",
       " 'axilares impresión mamas',\n",
       " 'mamas heterogéneamente densas']"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "max_sum_sim(doc_embedding, candidate_embeddings, candidates, top_n=5, nr_candidates=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['hallazgos mamas heterogéneamente',\n",
       " 'cuales visibles examen',\n",
       " 'posterior observa parcialmente',\n",
       " 'izquierda nodulitos cuadrantes',\n",
       " 'mama derecha cuadrante']"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "mmr(doc_embedding, candidate_embeddings, candidates, top_n=5, diversity=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting keybert\n  Downloading keybert-0.2.0.tar.gz (12 kB)\nRequirement already satisfied: sentence-transformers>=0.3.8 in c:\\python39\\lib\\site-packages (from keybert) (1.0.4)\nRequirement already satisfied: scikit-learn>=0.22.2 in c:\\python39\\lib\\site-packages (from keybert) (0.24.1)\nRequirement already satisfied: numpy>=1.18.5 in c:\\python39\\lib\\site-packages (from keybert) (1.20.2)\nRequirement already satisfied: scipy>=0.19.1 in c:\\python39\\lib\\site-packages (from scikit-learn>=0.22.2->keybert) (1.6.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in c:\\python39\\lib\\site-packages (from scikit-learn>=0.22.2->keybert) (2.1.0)\nRequirement already satisfied: joblib>=0.11 in c:\\python39\\lib\\site-packages (from scikit-learn>=0.22.2->keybert) (1.0.1)\nRequirement already satisfied: nltk in c:\\python39\\lib\\site-packages (from sentence-transformers>=0.3.8->keybert) (3.4.1)\nRequirement already satisfied: transformers<5.0.0,>=3.1.0 in c:\\python39\\lib\\site-packages (from sentence-transformers>=0.3.8->keybert) (4.4.2)\nRequirement already satisfied: sentencepiece in c:\\python39\\lib\\site-packages (from sentence-transformers>=0.3.8->keybert) (0.1.95)\nRequirement already satisfied: torch>=1.6.0 in c:\\python39\\lib\\site-packages (from sentence-transformers>=0.3.8->keybert) (1.8.1)\nRequirement already satisfied: tqdm in c:\\python39\\lib\\site-packages (from sentence-transformers>=0.3.8->keybert) (4.59.0)\nRequirement already satisfied: typing-extensions in c:\\python39\\lib\\site-packages (from torch>=1.6.0->sentence-transformers>=0.3.8->keybert) (3.7.4.3)\nRequirement already satisfied: filelock in c:\\python39\\lib\\site-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers>=0.3.8->keybert) (3.0.12)\nRequirement already satisfied: packaging in c:\\python39\\lib\\site-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers>=0.3.8->keybert) (20.9)\nRequirement already satisfied: tokenizers<0.11,>=0.10.1 in c:\\python39\\lib\\site-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers>=0.3.8->keybert) (0.10.1)\nRequirement already satisfied: sacremoses in c:\\python39\\lib\\site-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers>=0.3.8->keybert) (0.0.43)\nRequirement already satisfied: requests in c:\\python39\\lib\\site-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers>=0.3.8->keybert) (2.25.1)\nRequirement already satisfied: regex!=2019.12.17 in c:\\python39\\lib\\site-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers>=0.3.8->keybert) (2021.3.17)\nRequirement already satisfied: six in c:\\python39\\lib\\site-packages (from nltk->sentence-transformers>=0.3.8->keybert) (1.12.0)\nRequirement already satisfied: pyparsing>=2.0.2 in c:\\python39\\lib\\site-packages (from packaging->transformers<5.0.0,>=3.1.0->sentence-transformers>=0.3.8->keybert) (2.4.7)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\python39\\lib\\site-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers>=0.3.8->keybert) (1.26.4)\nRequirement already satisfied: idna<3,>=2.5 in c:\\python39\\lib\\site-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers>=0.3.8->keybert) (2.10)\nRequirement already satisfied: chardet<5,>=3.0.2 in c:\\python39\\lib\\site-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers>=0.3.8->keybert) (4.0.0)\nRequirement already satisfied: certifi>=2017.4.17 in c:\\python39\\lib\\site-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers>=0.3.8->keybert) (2020.12.5)\nRequirement already satisfied: click in c:\\python39\\lib\\site-packages (from sacremoses->transformers<5.0.0,>=3.1.0->sentence-transformers>=0.3.8->keybert) (7.1.2)\nBuilding wheels for collected packages: keybert\n  Building wheel for keybert (setup.py): started\n  Building wheel for keybert (setup.py): finished with status 'done'\n  Created wheel for keybert: filename=keybert-0.2.0-py3-none-any.whl size=10611 sha256=db19aef9a57aba11a8afa011e77e243d2f44ec1127adcdef898404006e7cf14c\n  Stored in directory: c:\\users\\eduardo\\appdata\\local\\pip\\cache\\wheels\\2b\\5e\\cb\\9bedeed618085f255420717d2960da9704821c46a9ffc1c3c3\nSuccessfully built keybert\nInstalling collected packages: keybert\nSuccessfully installed keybert-0.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install keybert\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keybert import KeyBERT\n",
    "\n",
    "doc = \"\"\"\n",
    "         Parénquima mamario denso, heterogéneo y pseudonodular, lo que disminuye la sensibilidad del método.\n",
    "En la unión de los cuadrantes inferiores, tercio posterior de la mama derecha, se visualiza nódulo isodenso, de bordes aceptablemente definidos, de 6mm., reducido de tamaño entre controles.\n",
    "No hay lesiones espiculadas, distorsiones ni microcalcificaciones agrupadas de sospecha, solo puntiformes aisladas. \n",
    "      \"\"\"\n",
    "model = KeyBERT('distilbert-base-nli-mean-tokens')\n",
    "keywords = model.extract_keywords(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('parénquima', 0.57),\n",
       " ('cuadrantes', 0.5348),\n",
       " ('aceptablemente', 0.5328),\n",
       " ('microcalcificaciones', 0.5078),\n",
       " ('agrupadas', 0.5056)]"
      ]
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "source": [
    "model.extract_keywords(doc, keyphrase_ngram_range=(1, 1), stop_words=stopwords.words('spanish'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('aceptablemente definidos', 0.6677),\n",
       " ('lesiones espiculadas', 0.6509),\n",
       " ('parénquima mamario', 0.6357),\n",
       " ('agrupadas sospecha', 0.6142),\n",
       " ('bordes aceptablemente', 0.6126)]"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "model.extract_keywords(doc, keyphrase_ngram_range=(1, 2), stop_words=stopwords.words('spanish'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('mamario denso heterogéneo', 0.7187),\n",
       " ('mama derecha visualiza', 0.6128),\n",
       " ('nódulo isodenso bordes', 0.6502),\n",
       " ('espiculadas distorsiones microcalcificaciones', 0.6667),\n",
       " ('definidos 6mm reducido', 0.5857)]"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "model.extract_keywords(doc, keyphrase_ngram_range=(3, 3), stop_words=stopwords.words('spanish'), \n",
    "                           use_maxsum=True, nr_candidates=20, top_n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('bordes aceptablemente definidos', 0.7187),\n",
       " ('solo puntiformes aisladas', 0.5748),\n",
       " ('6mm reducido tamaño', 0.6352),\n",
       " ('heterogéneo pseudonodular disminuye', 0.5857),\n",
       " ('posterior mama derecha', 0.6083)]"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "model.extract_keywords(doc, keyphrase_ngram_range=(3, 3), stop_words=stopwords.words('spanish'), \n",
    "                           use_mmr=True, diversity=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('hay lesiones espiculadas distorsiones ni microcalcificaciones', 0.8135),\n",
       " ('bordes aceptablemente definidos de 6mm reducido', 0.8039),\n",
       " ('mamario denso heterogéneo pseudonodular lo que', 0.7988),\n",
       " ('nódulo isodenso de bordes aceptablemente definidos', 0.7915),\n",
       " ('pseudonodular lo que disminuye la sensibilidad', 0.7902)]"
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "model.extract_keywords(doc, keyphrase_ngram_range=(6, 6), use_mmr=True, diversity=0.2,nr_candidates=20, top_n=5,stop_words=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\n         Parénquima mamario denso, heterogéneo y pseudonodular, lo que disminuye la sensibilidad del método.\\nEn la unión de los cuadrantes inferiores, tercio posterior de la mama derecha, se visualiza nódulo isodenso, de bordes aceptablemente definidos, de 6mm., reducido de tamaño entre controles.\\nNo hay lesiones espiculadas, distorsiones ni microcalcificaciones agrupadas de sospecha, solo puntiformes aisladas. \\n      '"
      ]
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}